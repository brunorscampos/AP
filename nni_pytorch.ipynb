{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 2.0.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: c:\\Users\\Utilizador\\anaconda3\\envs\\AP2\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.12.3\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.15.2+cpu\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 2.0.2\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "# para incluir os gráficos no nb\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from monai.transforms import Compose, LoadImage, AddChannel, ScaleIntensity, ToTensor, RandRotate, RandFlip, RandZoom\n",
    "from monai.networks.nets import densenet121\n",
    "from monai.metrics import compute_roc_auc\n",
    "from monai.utils import set_determinism\n",
    "from monai.config import print_config\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import nni\n",
    "np.random.seed(0)\n",
    "set_determinism(seed=0)\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelSpace(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, groups=in_ch)\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "\n",
    "\n",
    "@model_wrapper\n",
    "class ModelSpace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        # LayerChoice is used to select a layer between Conv2d and DwConv.\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            \n",
    "        # ValueChoice is used to select a dropout rate.\n",
    "        # ValueChoice can be used as parameter of modules wrapped in `nni.retiarii.nn.pytorch`\n",
    "        # or customized modules wrapped with `@basic_unit`.\n",
    "        self.dropout1 = nn.Dropout(nn.ValueChoice([0.25, 0.5, 0.75]))  # choose dropout rate from 0.25, 0.5 and 0.75\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        feature = nn.ValueChoice([64, 128, 256])\n",
    "        self.fc1 = nn.Linear(9216, feature)\n",
    "        self.fc2 = nn.Linear(feature, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(self.conv2(x), 2)\n",
    "        x = torch.flatten(self.dropout1(x), 1)\n",
    "        x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "model_space = ModelSpace()\n",
    "model_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.retiarii.strategy as strategy\n",
    "search_strategy = strategy.Random(dedup=True)  # dedup=False if deduplication is not wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image count: 10500\n",
      "Image dimensions: 256 x 256\n",
      "Label: agricultural    500 cases\n",
      "Label: airplane       500 cases\n",
      "Label: baseballdiamond    500 cases\n",
      "Label: beach          500 cases\n",
      "Label: buildings      500 cases\n",
      "Label: chaparral      500 cases\n",
      "Label: denseresidential    500 cases\n",
      "Label: forest         500 cases\n",
      "Label: freeway        500 cases\n",
      "Label: golfcourse     500 cases\n",
      "Label: harbor         500 cases\n",
      "Label: intersection    500 cases\n",
      "Label: mediumresidential    500 cases\n",
      "Label: mobilehomepark    500 cases\n",
      "Label: overpass       500 cases\n",
      "Label: parkinglot     500 cases\n",
      "Label: river          500 cases\n",
      "Label: runway         500 cases\n",
      "Label: sparseresidential    500 cases\n",
      "Label: storagetanks    500 cases\n",
      "Label: tenniscourt    500 cases\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'archive/images/'\n",
    "\n",
    "#conta os ficheiros do dataset por label\n",
    "def file_list(dir_path):\n",
    "    class_names = sorted([x for x in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, x))])\n",
    "    num_class = len(class_names)\n",
    "    image_files = [[os.path.join(dir_path, class_name, x) \n",
    "                    for x in os.listdir(os.path.join(dir_path, class_name))] \n",
    "                   for class_name in class_names] #constrói uma lista de listas de ficheiros por diretoria de classe\n",
    "    image_file_list = list()\n",
    "    image_label_list = list()\n",
    "    for i, class_name in enumerate(class_names): #para juntar as listas e construir a lista com os labels em numérico\n",
    "        image_file_list.extend(image_files[i])\n",
    "        image_label_list.extend([i] * len(image_files[i]))\n",
    "    return image_file_list, image_label_list, class_names\n",
    "\n",
    "image_file_list, image_label_list, class_names = file_list(DATA_DIR)\n",
    "print('Total image count:', len(image_label_list))\n",
    "image_width, image_height = Image.open(image_file_list[0]).size\n",
    "print(\"Image dimensions:\", image_width, \"x\", image_height)\n",
    "labels_cout= [image_label_list.count(x) for x in set(image_label_list)]\n",
    "for i,label in enumerate(class_names):\n",
    "    print(f\"Label: {label:11}  {labels_cout[i]:5d} cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training count = 8333\n",
      "Validation count = 1074\n",
      "Test count = 1093\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def holdout_dataset(image_file_list, image_label_list):\n",
    "    valid_frac, test_frac = 0.1, 0.1\n",
    "    trainX, trainY = list(), list()\n",
    "    valX, valY = list(), list()\n",
    "    testX, testY = list(), list()\n",
    "    for i in range(len(image_label_list)):\n",
    "        image_path = image_file_list[i]\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((32, 32))  # Resize image to 32x32\n",
    "        image_array = np.array(image)\n",
    "        if image_array.shape == (32, 32, 3):  # Check if the image has the desired size\n",
    "            rann = np.random.random()\n",
    "            if rann < valid_frac:\n",
    "                valX.append(image_array)\n",
    "                valY.append(image_label_list[i])\n",
    "            elif rann < test_frac + valid_frac:\n",
    "                testX.append(image_array)\n",
    "                testY.append(image_label_list[i])\n",
    "            else:\n",
    "                trainX.append(image_array)\n",
    "                trainY.append(image_label_list[i])\n",
    "    return trainX, trainY, valX, valY, testX, testY\n",
    "\n",
    "\n",
    "trainX, trainY, valX, valY, testX, testY = holdout_dataset(image_file_list,image_label_list)\n",
    "\n",
    "print(\"Training count =\",len(trainX))\n",
    "print(\"Validation count =\", len(valX))\n",
    "print(\"Test count =\",len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilizador\\anaconda3\\envs\\AP2\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Resize\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    AddChannel(),\n",
    "    ScaleIntensity(),\n",
    "    RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "    RandFlip(spatial_axis=0, prob=0.5),\n",
    "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5, keep_size=True),\n",
    "    Resize((32, 32)),  # Resize images to 32x32\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    AddChannel(),\n",
    "    ScaleIntensity(),\n",
    "    Resize((32, 32)),  # Resize images to 32x32\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "\n",
    "\n",
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "# test_ds = MedNISTDataset(testX, testY, val_transforms)\n",
    "# test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "@nni.trace\n",
    "def train_epoch(model, device, train_loader, optimizer, epoch):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "@nni.trace\n",
    "def test_epoch(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          correct, len(test_loader.dataset), accuracy))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "@nni.trace\n",
    "def evaluate_model(model_cls):\n",
    "    # \"model_cls\" is a class, need to instantiate\n",
    "    model = model_cls()\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to('cpu')\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    train_ds = MedNISTDataset(trainX, trainY, train_transforms)\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    \n",
    "    \n",
    "    val_ds = MedNISTDataset(valX, valY, val_transforms)\n",
    "    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE*2, num_workers=2)\n",
    "    \n",
    "    train_loader = train_dl\n",
    "    test_loader = val_dl\n",
    "\n",
    "    for epoch in range(3):\n",
    "        # train the model for one epoch\n",
    "        train_epoch(model, device, train_loader, optimizer, epoch)\n",
    "        # test the model for one epoch\n",
    "        accuracy = test_epoch(model, device, test_loader)\n",
    "        # call report intermediate result. Result can be float or dict\n",
    "        nni.report_intermediate_result(accuracy)\n",
    "\n",
    "    # report final test result\n",
    "    nni.report_final_result(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:50:46,207 - GPU available: True (cuda), used: True\n",
      "2023-06-02 23:50:46,207 - TPU available: False, using: 0 TPU cores\n",
      "2023-06-02 23:50:46,207 - IPU available: False, using: 0 IPUs\n",
      "2023-06-02 23:50:46,208 - HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import nni.retiarii.evaluator.pytorch.lightning as pl\n",
    "from nni.retiarii import serialize\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = serialize(MedNISTDataset,trainX, trainY, train_transforms)\n",
    "test_dataset = serialize(MedNISTDataset, testX, testY, val_transforms)\n",
    "\n",
    "evaluator = pl.Classification(\n",
    "    train_dataloader=pl.DataLoader(train_dataset, batch_size=100),\n",
    "    val_dataloaders=pl.DataLoader(test_dataset, batch_size=100),\n",
    "    max_epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config.max_trial_number = 4   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 1  # will run two trials concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-02 23:50:48] \u001b[32mCreating experiment, Experiment ID: \u001b[36mkzveobsn\u001b[0m\n",
      "2023-06-02 23:50:48,401 - Creating experiment, Experiment ID: ${CYAN}kzveobsn\n",
      "[2023-06-02 23:50:48] \u001b[32mStarting web server...\u001b[0m\n",
      "2023-06-02 23:50:48,407 - Starting web server...\n",
      "[2023-06-02 23:50:48] \u001b[32mSetting up...\u001b[0m\n",
      "2023-06-02 23:50:48,973 - Setting up...\n",
      "[2023-06-02 23:50:49] \u001b[32mWeb portal URLs: \u001b[36mhttp://192.168.0.218:8081 http://169.254.129.193:8081 http://192.168.33.1:8081 http://127.0.0.1:8081\u001b[0m\n",
      "2023-06-02 23:50:49,057 - Web portal URLs: ${CYAN}http://192.168.0.218:8081 http://169.254.129.193:8081 http://192.168.33.1:8081 http://127.0.0.1:8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilizador\\anaconda3\\envs\\AP2\\lib\\site-packages\\nni\\nas\\execution\\common\\integration_api.py:34: UserWarning: Advisor is already set.You should avoid instantiating RetiariiExperiment twice in one proces.If you are running in a Jupyter notebook, please restart the kernel.\n",
      "  warnings.warn('Advisor is already set.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-02 23:50:49] \u001b[32mDispatcher started\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilizador\\anaconda3\\envs\\AP2\\lib\\site-packages\\nni\\nas\\execution\\api.py:59: RuntimeWarning: Execution engine is already set. You should avoid instantiating RetiariiExperiment twice in one process. If you are running in a Jupyter notebook, please restart the kernel.\n",
      "  warnings.warn('Execution engine is already set. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-02 23:50:49,062 - Dispatcher started\n",
      "[2023-06-02 23:50:56] \u001b[32mStart strategy...\u001b[0m\n",
      "2023-06-02 23:50:56,233 - Start strategy...\n",
      "[2023-06-02 23:50:56] \u001b[32mSuccessfully update searchSpace.\u001b[0m\n",
      "2023-06-02 23:50:56,266 - Successfully update searchSpace.\n",
      "[2023-06-02 23:50:56] \u001b[32mRandom search running in fixed size mode. Dedup: on.\u001b[0m\n",
      "2023-06-02 23:50:56,267 - Random search running in fixed size mode. Dedup: on.\n",
      "[2023-06-02 23:57:58] \u001b[33mWARNING: KeyboardInterrupt detected\u001b[0m\n",
      "2023-06-02 23:57:58,575 - KeyboardInterrupt detected\n",
      "[2023-06-02 23:57:58] \u001b[32mStopping experiment, please wait...\u001b[0m\n",
      "2023-06-02 23:57:58,576 - Stopping experiment, please wait...\n",
      "[2023-06-02 23:57:58] \u001b[32mDispatcher exiting...\u001b[0m\n",
      "2023-06-02 23:57:58,596 - Dispatcher exiting...\n",
      "[2023-06-02 23:58:00] \u001b[32mDispatcher terminiated\u001b[0m\n",
      "2023-06-02 23:58:00,512 - Dispatcher terminiated\n",
      "[2023-06-02 23:58:00] \u001b[32mExperiment stopped\u001b[0m\n",
      "2023-06-02 23:58:00,514 - Experiment stopped\n",
      "[2023-06-02 23:58:00] \u001b[32mSearch process is done, the experiment is still alive, `stop()` can terminate the experiment.\u001b[0m\n",
      "2023-06-02 23:58:00,515 - Search process is done, the experiment is still alive, `stop()` can terminate the experiment.\n"
     ]
    }
   ],
   "source": [
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def evaluate_model_with_visualization(model_cls):\n",
    "    model = model_cls()\n",
    "    # dump the model into an onnx\n",
    "    if 'NNI_OUTPUT_DIR' in os.environ:\n",
    "        dummy_input = torch.zeros(1, 3, 32, 32)\n",
    "        torch.onnx.export(model, (dummy_input, ),\n",
    "                          Path(os.environ['NNI_OUTPUT_DIR']) / 'model.onnx')\n",
    "    evaluate_model(model_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_dict in exp.export_top_models(formatter='dict'):\n",
    "    print(model_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
